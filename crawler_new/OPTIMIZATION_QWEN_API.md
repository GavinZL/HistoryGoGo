# 千问 API 调用优化方案

## 📋 优化总结

### 问题1：能否一次性请求返回所有信息？
**✅ 已优化**

### 问题2：文本截断问题如何解决？
**✅ 已优化**

---

## 🎯 优化详情

### 1. **一次性提取所有数据**（减少API调用）

#### 优化前
```python
# 分两次调用
emperor_info = extract_emperor_info(html_wiki, html_baidu, page_name)  # 第1次API调用
events = extract_emperor_events(html_wiki, html_baidu, page_name)      # 第2次API调用
```

#### 优化后
```python
# 一次调用返回所有数据
result = extract_emperor_all_data(html_wiki, html_baidu, page_name)  # 只需1次API调用
emperor_info = result['emperor_info']
events = result['events']
```

#### 收益
- ✅ **减少50% API调用次数**（从2次降为1次）
- ✅ **节省API费用**
- ✅ **减少网络延迟**
- ✅ **保持上下文一致性**（基本信息和事迹的理解更连贯）

---

### 2. **文本传输限制优化**（充分利用千问上下文窗口）

#### 优化前的限制
```python
# 皇帝基本信息
wiki_content = cleaned_wiki[:3500]    # 只传 3500 字符
baidu_content = cleaned_baidu[:3500]   # 只传 3500 字符
# 总计：7000 字符

# 生平事迹
wiki_content = cleaned_wiki[:5000]    # 只传 5000 字符
baidu_content = cleaned_baidu[:5000]   # 只传 5000 字符
# 总计：10000 字符
```

#### 优化后的限制
```python
# 一次性提取（基本信息 + 生平事迹）
wiki_content = cleaned_wiki[:10000]    # 增加到 10000 字符
baidu_content = cleaned_baidu[:10000]  # 增加到 10000 字符
# 总计：20000 字符

# 如果降级为分次提取
# 皇帝基本信息
wiki_content = cleaned_wiki[:8000]     # 增加到 8000 字符
baidu_content = cleaned_baidu[:8000]   # 增加到 8000 字符
# 总计：16000 字符

# 生平事迹
wiki_content = cleaned_wiki[:10000]    # 增加到 10000 字符
baidu_content = cleaned_baidu[:10000]  # 增加到 10000 字符
# 总计：20000 字符
```

#### 对比

| 方案 | Wiki限制 | Baidu限制 | 总字符数 | 提升幅度 |
|------|---------|----------|---------|---------|
| **旧方案-基本信息** | 3500 | 3500 | 7000 | - |
| **新方案-基本信息** | 8000 | 8000 | 16000 | **+128%** |
| **旧方案-生平事迹** | 5000 | 5000 | 10000 | - |
| **新方案-生平事迹** | 10000 | 10000 | 20000 | **+100%** |
| **一次性提取** | 10000 | 10000 | 20000 | **+186%** (vs 旧方案基本信息) |

#### 收益
- ✅ **传输内容增加 2-3 倍**
- ✅ **数据完整性显著提升**
- ✅ **减少重要信息被截断的风险**

---

## 🔧 技术实现

### 新增方法：`extract_emperor_all_data()`

```python
def extract_emperor_all_data(
    self, 
    html_content_wiki: str, 
    html_content_baidu: str, 
    page_name: str
) -> Dict[str, Any]:
    """
    一次性提取皇帝所有信息（基本信息 + 生平事迹，融合双源数据）
    
    Returns:
        {
            "emperor_info": {
                "皇帝": "朱元璋",
                "庙号": "明太祖",
                ...
            },
            "events": [
                {
                    "时间": "1328年...",
                    "事件": "...",
                    "人物": [...],
                    ...
                }
            ]
        }
    """
```

### 降级机制

如果一次性提取失败（如 API 超时、返回格式错误），自动降级为分次提取：

```python
try:
    # 尝试一次性提取
    result = extract_emperor_all_data(...)
except Exception as e:
    # 降级为分次提取
    logger.warning("一次性提取失败，降级为分次提取模式...")
    emperor_info = extract_emperor_info(...)
    events = extract_emperor_events(...)
```

---

## 📊 千问模型上下文限制

### qwen-max（当前使用）
- **上下文窗口**: 约 30,000 tokens（≈ 20,000 汉字）
- **当前使用**: 20,000 字符（约 13,000 tokens）
- **剩余空间**: 充足 ✅

### qwen-long（可选）
- **上下文窗口**: 最高 1,000,000 tokens
- **适用场景**: 需要处理更长内容时
- **缺点**: 响应速度较慢

---

## 💡 进一步优化方案（可选）

### 方案A：智能内容提取
只提取关键部分，移除冗余内容：

```python
def _extract_key_sections(self, html_content: str, data_source: str) -> str:
    """提取关键章节（infobox、生平、大事记等）"""
    soup = BeautifulSoup(html_content, 'lxml')
    
    if data_source == 'wikipedia':
        # 提取 infobox
        infobox = soup.find('table', class_='infobox')
        # 提取生平章节
        biography = soup.find('h2', text='生平')
        # ...
    
    return key_content
```

### 方案B：分段处理长内容
对于超长内容，分段提取后合并：

```python
# 第1段：早期生涯（前10000字符）
# 第2段：中期统治（10000-20000字符）
# 第3段：晚年时期（20000-30000字符）
```

### 方案C：使用 qwen-long 模型
适合需要处理完整长文的场景：

```python
QWEN_MODEL = 'qwen-long'  # 支持更长上下文
```

---

## 🚀 使用方法

### 默认（推荐）
一次性提取，失败时自动降级：

```bash
# 无需修改，直接运行
python run_crawler.py --source both --mode test
```

### 强制分次提取（兼容旧版）
如果需要强制使用分次提取模式，可以在代码中注释一次性提取部分。

---

## 📈 性能对比

### API 调用次数
| 场景 | 旧方案 | 新方案 | 节省 |
|------|--------|--------|------|
| 1位皇帝 | 2次 | 1次 | **50%** |
| 3位皇帝（测试） | 6次 | 3次 | **50%** |
| 16位皇帝（全量） | 32次 | 16次 | **50%** |

### 传输数据量
| 场景 | 旧方案 | 新方案 | 提升 |
|------|--------|--------|------|
| 单次请求（基本信息） | 7000字符 | 16000字符 | **+128%** |
| 单次请求（生平事迹） | 10000字符 | 20000字符 | **+100%** |
| 一次性提取 | 分2次共17000字符 | 1次20000字符 | **+18%** |

### 数据完整性
- ✅ **基本信息更完整**（从 3500 → 8000/10000 字符）
- ✅ **事迹详情更丰富**（从 5000 → 10000 字符）
- ✅ **重要人物链接不易遗漏**

---

## 📝 日志示例

### 优化后的日志
```
================================================================================
🤖 [大模型提取] 开始提取皇帝信息
   皇帝: 朱元璋
   Wikipedia HTML: 413635 字符
   Baidu HTML: 387542 字符
   提取模式: 一次性提取（基本信息 + 生平事迹）
   传输限制: Wiki 10000字符 + Baidu 10000字符
================================================================================

🚀 [大模型调用] 一次性提取所有数据...
   ✅ 数据提取完成

📑 [基本信息]
   皇帝: 朱元璋
   庙号: 明太祖
   年号: 洪武
   出生: 1328年10月21日（元天历元年九月十八日）
   去世: 1398年6月24日（洪武三十一年闰五月初十）

📜 [生平事迹] 提取完成: 18 条
      1. 1328年10月29日（元天历元年九月十八日） - 出生于贫农家庭，原名朱重八...
      2. 1344年（至正四年） - 淮北大旱，父母兄长相继去世...
      3. 1352年 - 受儿时好友汤和邀请投奔郭子兴...
      ... 还有 15 条事迹
```

### 降级模式日志
```
🚀 [大模型调用] 一次性提取所有数据...
   ⚠️  一次性提取失败: API timeout
   🔄 降级为分次提取模式...

📑 [Step 1] 调用大模型提取皇帝基本信息...
   ✅ 皇帝信息提取完成

📜 [Step 2] 调用大模型提取生平事迹...
   ✅ 生平事迹提取完成: 18 条
```

---

## 🎯 总结

### 主要改进
1. ✅ **减少50% API调用**：从2次合并为1次
2. ✅ **传输量提升2-3倍**：充分利用千问上下文窗口
3. ✅ **智能降级机制**：失败时自动回退到分次提取
4. ✅ **向后兼容**：保留旧方法，确保稳定性

### 适用场景
- ✅ **推荐使用**：一次性提取（`extract_emperor_all_data`）
- ✅ **备用方案**：分次提取（自动降级）
- ⚠️ **特殊需求**：超长内容可考虑 qwen-long 模型

---

**更新时间**: 2025-12-14  
**版本**: v1.3  
**优化内容**: 千问API调用优化 + 文本传输限制优化
