# Crawler_new å¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸš€ 5åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹

### ç¬¬ä¸€æ­¥ï¼šé…ç½®åƒé—® API Key

ç¼–è¾‘ `crawler_new/config/settings.py`ï¼š

```python
# åƒé—®å¤§æ¨¡å‹é…ç½®
QWEN_API_KEY = 'sk-your-api-key-here'  # ğŸ‘ˆ å¡«å…¥ä½ çš„ API Key
```

> ğŸ’¡ è·å– API Keyï¼šè®¿é—® [é˜¿é‡Œäº‘ç™¾ç‚¼å¹³å°](https://dashscope.console.aliyun.com/)

### ç¬¬äºŒæ­¥ï¼šåˆ›å»ºæ•°æ®ç›®å½•

```bash
mkdir -p crawler_new/data/html/{emperor,event,person}
mkdir -p crawler_new/data/logs
```

### ç¬¬ä¸‰æ­¥ï¼šè¿è¡Œæµ‹è¯•

```bash
cd crawler_new
python run_crawler.py --source wikipedia --mode test
```

è¿™å°†ï¼š
- âœ… çˆ¬å–å‰3ä½æ˜æœçš‡å¸çš„ Wikipedia **å’Œ**ç™¾åº¦ç™¾ç§‘é¡µé¢
- âœ… ä¿å­˜ HTML åˆ° `data/html/emperor/`
- âœ… è°ƒç”¨åƒé—®å¤§æ¨¡å‹**èåˆåŒæºHTML**æå–ç»“æ„åŒ–æ•°æ®
- âœ… è¾“å‡ºæ—¥å¿—åˆ°æ§åˆ¶å°

### é¢„æœŸç»“æœ

è¿è¡Œå®Œæˆåï¼Œä½ ä¼šçœ‹åˆ°ï¼š

```
crawler_new/data/html/emperor/
â”œâ”€â”€ ming_emperor_001_wikipedia.html
â”œâ”€â”€ ming_emperor_001_wikipedia_metadata.json
â”œâ”€â”€ ming_emperor_002_wikipedia.html
â”œâ”€â”€ ming_emperor_002_wikipedia_metadata.json
â”œâ”€â”€ ming_emperor_003_wikipedia.html
â””â”€â”€ ming_emperor_003_wikipedia_metadata.json
```

## ğŸ“Š è¿›é˜¶ä½¿ç”¨

### çˆ¬å–ç™¾åº¦ç™¾ç§‘

```bash
python run_crawler.py --source baidu --mode test
```

### ğŸŒŸ åŒæºèåˆçˆ¬å–ï¼ˆæ¨èï¼‰

```bash
python run_crawler.py --source both --mode test
```

**åŒæºèåˆçš„ä¼˜åŠ¿ï¼š**
- âœ… åŒæ—¶ä¸‹è½½ Wikipedia å’Œç™¾åº¦ç™¾ç§‘çš„ HTML
- âœ… åƒé—®å¤§æ¨¡å‹å°†ä¸¤ä»½èµ„æ–™äº’ä¸ºè¡¥å……ï¼Œå½¢æˆæ›´å®Œæ•´çš„æ•°æ®
- âœ… æé«˜æ•°æ®å‡†ç¡®æ€§å’Œå®Œæ•´æ€§

### å…¨é‡çˆ¬å–ï¼ˆ16ä½çš‡å¸ï¼‰

```bash
python run_crawler.py --source wikipedia --mode full
```

### ç¦ç”¨é€’å½’çˆ¬å–

ç¼–è¾‘ `config/settings.py`ï¼š

```python
ENABLE_RECURSIVE_CRAWL = False
```

## ğŸ” æŸ¥çœ‹æå–ç»“æœ

æ‰“å¼€ `data/html/emperor/ming_emperor_001_wikipedia_metadata.json`ï¼Œä½ ä¼šçœ‹åˆ°ï¼š

```json
{
  "page_type": "emperor",
  "page_id": "ming_emperor_001_wikipedia",
  "page_name": "æœ±å…ƒç’‹",
  "data_source": "wikipedia",
  "source_url": "https://zh.wikipedia.org/wiki/æœ±å…ƒç’‹",
  "crawl_time": "2025-12-14T22:45:00",
  "metadata": {
    "temple_name": "æ˜å¤ªç¥–",
    "reign_title": "æ´ªæ­¦",
    "dynasty_order": 1
  }
}
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **API é™æµ**ï¼šåƒé—® API æœ‰è°ƒç”¨é¢‘ç‡é™åˆ¶ï¼Œå»ºè®®æµ‹è¯•æ¨¡å¼å…ˆè¡Œ
2. **è´¹ç”¨**ï¼šåƒé—® API æŒ‰è°ƒç”¨æ¬¡æ•°æ”¶è´¹ï¼Œæ³¨æ„æ§åˆ¶æˆæœ¬
3. **ç½‘ç»œ**ï¼šç¡®ä¿èƒ½è®¿é—® Wikipedia å’Œç™¾åº¦ç™¾ç§‘
4. **ä¾èµ–**ï¼šè¿è¡Œå‰ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–ï¼š`pip install -r requirements.txt`

## ğŸ› å¸¸è§é—®é¢˜

### Q: API Key é”™è¯¯

```
âŒ è°ƒç”¨åƒé—®APIå¤±è´¥: 401 Unauthorized
```

**è§£å†³**ï¼šæ£€æŸ¥ `QWEN_API_KEY` æ˜¯å¦æ­£ç¡®ï¼Œè´¦æˆ·æ˜¯å¦æœ‰ä½™é¢ã€‚

### Q: ç½‘ç»œè¿æ¥å¤±è´¥

```
âŒ æˆåŠŸè·å– HTML å¤±è´¥: Connection timeout
```

**è§£å†³**ï¼šæ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œæˆ–ä½¿ç”¨ä»£ç†ã€‚

### Q: åªæƒ³ä¸‹è½½ HTMLï¼Œä¸è°ƒç”¨å¤§æ¨¡å‹

**è§£å†³**ï¼šå°† `QWEN_API_KEY` è®¾ä¸ºç©ºå­—ç¬¦ä¸²ï¼š

```python
QWEN_API_KEY = ''
```

## ğŸ“š ä¸‹ä¸€æ­¥

- æŸ¥çœ‹å®Œæ•´æ–‡æ¡£ï¼š[README.md](README.md)
- äº†è§£æ•°æ®æµç¨‹ï¼šæŸ¥çœ‹å„ä¸ª Pipeline çš„ä»£ç 
- æ‰©å±•åŠŸèƒ½ï¼šå®ç°äººç‰©ã€äº‹ä»¶çš„æå–é€»è¾‘
- æ•°æ®åº“å­˜å‚¨ï¼šå®Œå–„ SQLite å’Œ Neo4j Pipeline

## ğŸ¯ å¿«é€Ÿæµ‹è¯•å‘½ä»¤æ±‡æ€»

```bash
# æµ‹è¯•æ¨¡å¼ - Wikipedia
python run_crawler.py --source wikipedia --mode test

# æµ‹è¯•æ¨¡å¼ - ç™¾åº¦ç™¾ç§‘
python run_crawler.py --source baidu --mode test

# æµ‹è¯•æ¨¡å¼ - åŒæº
python run_crawler.py --source both --mode test

# å…¨é‡æ¨¡å¼
python run_crawler.py --source wikipedia --mode full

# ä½¿ç”¨ Scrapy å‘½ä»¤
scrapy crawl ming_emperor -s CRAWL_MODE=test
```

ç¥ä½ ä½¿ç”¨æ„‰å¿«ï¼ğŸ‰
