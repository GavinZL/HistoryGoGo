"""
SQLite å­˜å‚¨ Pipeline
å°†æå–çš„ç»“æ„åŒ–æ•°æ®å­˜å…¥ SQLite æ•°æ®åº“
"""

from crawler_new.models.items import ExtractedDataItem


class SQLitePipeline:
    """SQLiteå­˜å‚¨Pipeline"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.conn = None
    
    @classmethod
    def from_crawler(cls, crawler):
        db_path = crawler.settings.get('SQLITE_DB_PATH', 'server/database/historygogo.db')
        return cls(db_path)
    
    def open_spider(self, spider):
        """Spider å¼€å¯æ—¶è¿æ¥æ•°æ®åº“"""
        spider.logger.info(f"ğŸ’¾ SQLite Pipeline å·²åˆå§‹åŒ–: {self.db_path}")
        spider.logger.info("   ï¼ˆæ•°æ®åº“å­˜å‚¨åŠŸèƒ½å¾…å®ç°ï¼Œéœ€å¤ç”¨ crawler çš„ SQLite Pipeline é€»è¾‘ï¼‰")
    
    def close_spider(self, spider):
        """Spider å…³é—­æ—¶æ–­å¼€æ•°æ®åº“è¿æ¥"""
        if self.conn:
            self.conn.close()
    
    def process_item(self, item, spider):
        """å¤„ç† Item"""
        # åªå¤„ç† ExtractedDataItem
        if not isinstance(item, ExtractedDataItem):
            return item
        
        try:
            # TODO: å®ç°æ•°æ®åº“å­˜å‚¨é€»è¾‘
            # 1. è§£æ extracted_data
            # 2. è½¬æ¢ä¸º crawler.models.entities ä¸­çš„æ•°æ®æ¨¡å‹
            # 3. å­˜å…¥ SQLite æ•°æ®åº“
            
            spider.logger.info(f"ğŸ’¾ SQLiteå­˜å‚¨: {item['html_item']['page_id']}ï¼ˆå¾…å®ç°ï¼‰")
            
        except Exception as e:
            spider.logger.error(f"âŒ SQLiteå­˜å‚¨å¤±è´¥: {item['html_item']['page_id']}, é”™è¯¯: {str(e)}")
        
        return item
