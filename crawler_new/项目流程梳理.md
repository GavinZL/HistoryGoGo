# crawler_new é¡¹ç›®æµç¨‹æ¢³ç†

> **ç›®æ ‡**: çˆ¬å– Wikipedia å†…å®¹ â†’ å­˜å‚¨ HTML â†’ æå–æ–‡æœ¬ â†’ æœ¬åœ° LLM ç»“æ„åŒ– â†’ å­˜å‚¨åˆ° SQLite å’Œ Neo4j

---

## ğŸ“‹ æ•´ä½“æµç¨‹å›¾

```
1ï¸âƒ£ çˆ¬å– Wikipedia HTML
   â†“
2ï¸âƒ£ å­˜å‚¨ HTML æ–‡ä»¶
   â†“
3ï¸âƒ£ æå– HTML æ–‡æœ¬å†…å®¹ï¼ˆç”Ÿå¹³äº‹è¿¹ä»‹ç»ï¼‰
   â†“
4ï¸âƒ£ æœ¬åœ° Qwen2.5:14b æ¨¡å‹ç»“æ„åŒ–å¤„ç†
   â†“
5ï¸âƒ£ JSON æ•°æ®è¾“å‡º
   â†“
6ï¸âƒ£ åŒæ—¶å­˜å‚¨åˆ° SQLite å’Œ Neo4j
```

---

## ğŸ—‚ï¸ ç›®å½•ç»“æ„ä¸åŠŸèƒ½è¯´æ˜

### **æ ¸å¿ƒæ–‡ä»¶**

```
crawler_new/
â”œâ”€â”€ run_crawler.py              # ğŸš€ çˆ¬è™«å¯åŠ¨è„šæœ¬
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.py             # âš™ï¸ å…¨å±€é…ç½®ï¼ˆPipelineé¡ºåºã€æ•°æ®åº“ã€LLMé…ç½®ï¼‰
â”‚   â””â”€â”€ ming_data.py            # ğŸ“Š æ˜æœçš‡å¸æ•°æ®æº
â”œâ”€â”€ spiders/
â”‚   â””â”€â”€ ming_emperor_spider.py  # ğŸ•·ï¸ Wikipediaçˆ¬è™«ï¼ˆåªçˆ¬Wikipediaï¼Œç§»é™¤ç™¾åº¦ï¼‰
â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ html_storage_pipeline.py       # ğŸ’¾ Pipeline-1: HTMLå­˜å‚¨
â”‚   â”œâ”€â”€ qwen_extraction_pipeline.py    # ğŸ¤– Pipeline-2: æ–‡æœ¬æå–+LLMå¤„ç†
â”‚   â”œâ”€â”€ data_validation_pipeline.py    # âœ… Pipeline-3: æ•°æ®éªŒè¯
â”‚   â”œâ”€â”€ sqlite_pipeline.py             # ğŸ’¾ Pipeline-4: SQLiteå­˜å‚¨
â”‚   â””â”€â”€ neo4j_pipeline.py              # ğŸ”— Pipeline-5: Neo4jå­˜å‚¨
â”œâ”€â”€ local_llm/
â”‚   â””â”€â”€ local_extractor.py      # ğŸ§  æœ¬åœ°Qwen2.5:14bæå–å™¨
â””â”€â”€ models/
    â””â”€â”€ items.py                # ğŸ“¦ æ•°æ®æ¨¡å‹å®šä¹‰
```

---

## ğŸ”„ è¯¦ç»†æµç¨‹è¯´æ˜

### **ç¬¬1æ­¥ï¼šçˆ¬å– Wikipedia HTML**
- **æ–‡ä»¶**: `spiders/ming_emperor_spider.py`
- **åŠŸèƒ½**: 
  - åªçˆ¬å– Wikipedia çš„ HTML é¡µé¢
  - ç§»é™¤ç™¾åº¦ç™¾ç§‘ç›¸å…³ä»£ç 
  - ç”Ÿæˆ `HtmlPageItem` å¯¹è±¡

**éœ€è¦è°ƒæ•´**:
```python
# å½“å‰ä»£ç æ”¯æŒ wikipedia/baidu/both
# è°ƒæ•´ä¸ºåªçˆ¬å– wikipedia
source = 'wikipedia'  # å›ºå®šä¸º wikipedia
```

---

### **ç¬¬2æ­¥ï¼šå­˜å‚¨ HTML æ–‡ä»¶**
- **æ–‡ä»¶**: `pipelines/html_storage_pipeline.py`
- **åŠŸèƒ½**:
  - å°† HTML å­˜å‚¨åˆ° `crawler_new/data/html/emperor/` ç›®å½•
  - ç”Ÿæˆå…ƒæ•°æ® JSON æ–‡ä»¶
- **è¾“å‡º**:
  ```
  crawler_new/data/html/emperor/
  â”œâ”€â”€ ming_emperor_001_wikipedia.html
  â””â”€â”€ ming_emperor_001_wikipedia_metadata.json
  ```

**çŠ¶æ€**: âœ… å·²å®ç°ï¼Œæ— éœ€ä¿®æ”¹

---

### **ç¬¬3æ­¥ï¼šæå– HTML æ–‡æœ¬å†…å®¹**
- **æ–‡ä»¶**: `local_llm/local_extractor.py` çš„ `_clean_html()` æ–¹æ³•
- **åŠŸèƒ½**:
  - ä½¿ç”¨ BeautifulSoup è§£æ HTML
  - ç§»é™¤è„šæœ¬ã€æ ·å¼ã€å¯¼èˆªç­‰æ— å…³å†…å®¹
  - æå–ä¸»è¦æ–‡æœ¬ï¼ˆWikipedia çš„ `mw-parser-output` éƒ¨åˆ†ï¼‰
  - **é‡ç‚¹**: æå–ç”Ÿå¹³äº‹è¿¹ä»‹ç»æ–‡æœ¬

**éœ€è¦ä¼˜åŒ–**:
```python
def _clean_html(self, html_content: str, data_source: str) -> str:
    """
    æ¸…ç† HTMLï¼Œæå–ä¸»è¦æ–‡æœ¬ï¼ˆç”Ÿå¹³äº‹è¿¹ï¼‰
    """
    soup = BeautifulSoup(html_content, 'lxml')
    
    # ç§»é™¤æ— å…³æ ‡ç­¾
    for tag in soup(['script', 'style', 'nav', 'footer', 'header']):
        tag.decompose()
    
    # Wikipediaï¼šæå–ä¸»ä½“å†…å®¹
    if data_source == 'wikipedia':
        main_content = soup.find('div', class_='mw-parser-output')
        if main_content:
            # é‡ç‚¹æå–æ®µè½æ–‡æœ¬ï¼ˆç”Ÿå¹³äº‹è¿¹ï¼‰
            return main_content.get_text(separator='\n', strip=True)
    
    return soup.get_text(separator='\n', strip=True)
```

---

### **ç¬¬4æ­¥ï¼šæœ¬åœ° Qwen2.5:14b æ¨¡å‹ç»“æ„åŒ–å¤„ç†**
- **æ–‡ä»¶**: `local_llm/local_extractor.py` çš„ `extract_emperor_all_data()` æ–¹æ³•
- **åŠŸèƒ½**:
  - æ¥æ”¶æ¸…ç†åçš„æ–‡æœ¬
  - è°ƒç”¨æœ¬åœ° Ollama APIï¼ˆQwen2.5:14bï¼‰
  - ä½¿ç”¨ç»“æ„åŒ–æç¤ºè¯å¼•å¯¼æ¨¡å‹è¾“å‡º JSON

**å½“å‰å®ç°**:
```python
def extract_emperor_all_data(self, html_content_wiki: str, page_name: str):
    # 1. æ¸…ç† HTML â†’ æå–æ–‡æœ¬
    cleaned_text = self._clean_html(html_content_wiki, 'wikipedia')
    
    # 2. æ„å»ºæç¤ºè¯
    prompt = self._build_emperor_all_data_prompt(cleaned_text, page_name)
    
    # 3. è°ƒç”¨ Ollama API
    response_text = self._call_local_llm(prompt)
    
    # 4. è§£æ JSON å“åº”
    result = self._parse_emperor_all_data_response(response_text)
    
    return result
```

**éœ€è¦è°ƒæ•´**:
- ç§»é™¤ç™¾åº¦ç™¾ç§‘ç›¸å…³å‚æ•°
- åªå¤„ç† Wikipedia å•ä¸€æ•°æ®æº

---

### **ç¬¬5æ­¥ï¼šJSON æ•°æ®è¾“å‡º**
- **è¾“å‡ºæ ¼å¼**:
```json
{
  "emperor_info": {
    "çš‡å¸": "æœ±å…ƒç’‹",
    "åº™å·": "æ˜å¤ªç¥–",
    "å¹´å·": "æ´ªæ­¦",
    "å‡ºç”Ÿ": "1328å¹´10æœˆ21æ—¥ï¼ˆå…ƒå¤©å†å…ƒå¹´ä¹æœˆåå…«æ—¥ï¼‰",
    "å»ä¸–": "1398å¹´6æœˆ24æ—¥ï¼ˆæ´ªæ­¦ä¸‰åä¸€å¹´é—°äº”æœˆåˆåï¼‰",
    "ç®€ä»‹": "æ˜æœå¼€å›½çš‡å¸..."
  },
  "events": [
    {
      "æ—¶é—´": "1328å¹´10æœˆ29æ—¥",
      "äº‹ä»¶": "å‡ºç”Ÿäºè´«å†œå®¶åº­...",
      "äº‹ä»¶å½±å“": "å¡‘é€ äº†æœ±å…ƒç’‹çš„å¹³æ°‘æ„è¯†",
      "äººç‰©": [
        {"å§“å": "æœ±äº”å››", "å…³ç³»": "çˆ¶", "é“¾æ¥": "https://..."}
      ],
      "åœ°ç‚¹": "æ¿ å·é’Ÿç¦»å¿ä¸œä¹¡ï¼ˆä»Šå®‰å¾½çœå‡¤é˜³å¿ï¼‰"
    }
  ]
}
```

**çŠ¶æ€**: âœ… å·²å®ç°

---

### **ç¬¬6æ­¥ï¼šå­˜å‚¨åˆ° SQLite å’Œ Neo4j**

#### **SQLite å­˜å‚¨**
- **æ–‡ä»¶**: `pipelines/sqlite_pipeline.py`
- **å½“å‰çŠ¶æ€**: âš ï¸ å¾…å®ç°
- **éœ€è¦å®ç°**:
  ```python
  def process_item(self, item, spider):
      if not isinstance(item, ExtractedDataItem):
          return item
      
      # 1. è¿æ¥æ•°æ®åº“
      # 2. è§£æ extracted_data
      # 3. æ’å…¥ emperors è¡¨
      # 4. æ’å…¥ events è¡¨
      # 5. æäº¤äº‹åŠ¡
  ```

#### **Neo4j å­˜å‚¨**
- **æ–‡ä»¶**: `pipelines/neo4j_pipeline.py`
- **å½“å‰çŠ¶æ€**: âš ï¸ å¾…å®ç°
- **éœ€è¦å®ç°**:
  ```python
  def process_item(self, item, spider):
      if not isinstance(item, ExtractedDataItem):
          return item
      
      # 1. è¿æ¥ Neo4j
      # 2. åˆ›å»ºçš‡å¸èŠ‚ç‚¹
      # 3. åˆ›å»ºäº‹ä»¶èŠ‚ç‚¹
      # 4. åˆ›å»ºäººç‰©èŠ‚ç‚¹
      # 5. åˆ›å»ºå…³ç³»è¾¹
  ```

---

## âš™ï¸ é…ç½®è¯´æ˜

### **settings.py å…³é”®é…ç½®**

```python
# Pipeline æ‰§è¡Œé¡ºåºï¼ˆæ•°å­—è¶Šå°è¶Šå…ˆæ‰§è¡Œï¼‰
ITEM_PIPELINES = {
    'crawler_new.pipelines.html_storage_pipeline.HtmlStoragePipeline': 100,
    'crawler_new.pipelines.qwen_extraction_pipeline.QwenExtractionPipeline': 200,
    'crawler_new.pipelines.data_validation_pipeline.DataValidationPipeline': 300,
    'crawler_new.pipelines.sqlite_pipeline.SQLitePipeline': 400,
    'crawler_new.pipelines.neo4j_pipeline.Neo4jPipeline': 500,
}

# æœ¬åœ° LLM é…ç½®
USE_LOCAL_LLM = True
LOCAL_LLM_MODEL = 'qwen2.5:14b'
LOCAL_LLM_BASE_URL = 'http://localhost:11434'

# æ•°æ®åº“é…ç½®
SQLITE_DB_PATH = 'server/database/historygogo.db'
NEO4J_URI = 'bolt://localhost:7687'
NEO4J_USER = 'neo4j'
NEO4J_PASSWORD = 'Ls_gavin_08'

# çˆ¬å–æ¨¡å¼
CRAWL_MODE = 'test'  # 'test' æˆ– 'full'
TEST_EMPEROR_COUNT = 3
```

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### **1. å¯åŠ¨çˆ¬è™«**
```bash
cd /Users/bigo/Documents/AI/App/HistoryGoGo

# æµ‹è¯•æ¨¡å¼ï¼ˆçˆ¬å–å‰3ä½çš‡å¸ï¼‰
python crawler_new/run_crawler.py --source wikipedia --mode test

# å…¨é‡æ¨¡å¼ï¼ˆçˆ¬å–æ‰€æœ‰çš‡å¸ï¼‰
python crawler_new/run_crawler.py --source wikipedia --mode full
```

### **2. ç¡®ä¿ Ollama æœåŠ¡è¿è¡Œ**
```bash
# å¯åŠ¨ Ollama
ollama serve

# éªŒè¯æ¨¡å‹å¯ç”¨
ollama list
# åº”è¯¥çœ‹åˆ° qwen2.5:14b
```

### **3. æŸ¥çœ‹è¾“å‡ºæ•°æ®**
```bash
# HTML æ–‡ä»¶
ls crawler_new/data/html/emperor/

# Qwen å“åº”ï¼ˆJSONï¼‰
ls crawler_new/data/html/qwen_responses/

# SQLite æ•°æ®åº“
sqlite3 server/database/historygogo.db "SELECT * FROM emperors;"

# Neo4j æ•°æ®
# è®¿é—® http://localhost:7474
```

---

## ğŸ“ éœ€è¦è°ƒæ•´çš„å†…å®¹

### **ğŸ”´ é«˜ä¼˜å…ˆçº§ï¼ˆå¿…é¡»ä¿®æ”¹ï¼‰**

1. **ç§»é™¤ç™¾åº¦ç™¾ç§‘ç›¸å…³ä»£ç **
   - æ–‡ä»¶: `spiders/ming_emperor_spider.py`
   - æ“ä½œ: ç§»é™¤ `baidu_url` ç›¸å…³çˆ¬å–é€»è¾‘
   
2. **ç®€åŒ– LLM æå–å™¨**
   - æ–‡ä»¶: `local_llm/local_extractor.py`
   - æ“ä½œ: ç§»é™¤åŒæºèåˆé€»è¾‘ï¼Œåªå¤„ç† Wikipedia å•ä¸€æ•°æ®æº

3. **å®ç° SQLite Pipeline**
   - æ–‡ä»¶: `pipelines/sqlite_pipeline.py`
   - æ“ä½œ: å®ç°æ•°æ®åº“æ’å…¥é€»è¾‘

4. **å®ç° Neo4j Pipeline**
   - æ–‡ä»¶: `pipelines/neo4j_pipeline.py`
   - æ“ä½œ: å®ç°å›¾æ•°æ®åº“èŠ‚ç‚¹å’Œå…³ç³»åˆ›å»º

### **ğŸŸ¡ ä¸­ä¼˜å…ˆçº§ï¼ˆå»ºè®®ä¿®æ”¹ï¼‰**

5. **ä¼˜åŒ–æ–‡æœ¬æå–**
   - æ–‡ä»¶: `local_llm/local_extractor.py` çš„ `_clean_html()`
   - æ“ä½œ: æ›´ç²¾ç¡®åœ°æå–ç”Ÿå¹³äº‹è¿¹æ®µè½

6. **ç§»é™¤é€’å½’çˆ¬å–**
   - æ–‡ä»¶: `pipelines/recursive_crawl_pipeline.py`
   - æ“ä½œ: ä» Pipeline ä¸­ç§»é™¤æˆ–ç¦ç”¨

### **ğŸŸ¢ ä½ä¼˜å…ˆçº§ï¼ˆå¯é€‰ï¼‰**

7. **ç®€åŒ– Pipeline é…ç½®**
   - æ–‡ä»¶: `config/settings.py`
   - æ“ä½œ: ç§»é™¤ä¸éœ€è¦çš„ Pipeline

---

## ğŸ¯ ä¸‹ä¸€æ­¥æ“ä½œå»ºè®®

### **é˜¶æ®µ1ï¼šä»£ç ç®€åŒ–ï¼ˆåªçˆ¬ Wikipediaï¼‰**
1. ä¿®æ”¹ `ming_emperor_spider.py`ï¼šç§»é™¤ç™¾åº¦ç™¾ç§‘
2. ä¿®æ”¹ `local_extractor.py`ï¼šç§»é™¤åŒæºèåˆ
3. ä¿®æ”¹ `qwen_extraction_pipeline.py`ï¼šç§»é™¤åŒæºç­‰å¾…é€»è¾‘

### **é˜¶æ®µ2ï¼šå®ç°æ•°æ®å­˜å‚¨**
1. å®ç° `sqlite_pipeline.py`ï¼šæ’å…¥çš‡å¸å’Œäº‹ä»¶æ•°æ®
2. å®ç° `neo4j_pipeline.py`ï¼šåˆ›å»ºèŠ‚ç‚¹å’Œå…³ç³»

### **é˜¶æ®µ3ï¼šæµ‹è¯•éªŒè¯**
1. è¿è¡Œæµ‹è¯•æ¨¡å¼ï¼ˆ3ä½çš‡å¸ï¼‰
2. éªŒè¯ HTML å­˜å‚¨
3. éªŒè¯ JSON æå–
4. éªŒè¯æ•°æ®åº“å­˜å‚¨
5. éªŒè¯ Neo4j å›¾è°±

---

## ğŸ“Š æ•°æ®æµè½¬ç¤ºæ„å›¾

```
Wikipedia HTML
      â†“
HtmlPageItem (Spider ç”Ÿæˆ)
      â†“
Pipeline-1: HtmlStoragePipeline
      â”œâ”€ å­˜å‚¨ HTML æ–‡ä»¶
      â””â”€ å­˜å‚¨å…ƒæ•°æ® JSON
      â†“
Pipeline-2: QwenExtractionPipeline
      â”œâ”€ æ¸…ç† HTML â†’ æå–æ–‡æœ¬
      â”œâ”€ è°ƒç”¨ Qwen2.5:14b
      â””â”€ ç”Ÿæˆ ExtractedDataItem
      â†“
Pipeline-3: DataValidationPipeline
      â””â”€ éªŒè¯æ•°æ®å®Œæ•´æ€§
      â†“
Pipeline-4: SQLitePipeline
      â””â”€ å­˜å‚¨åˆ°å…³ç³»å‹æ•°æ®åº“
      â†“
Pipeline-5: Neo4jPipeline
      â””â”€ å­˜å‚¨åˆ°å›¾æ•°æ®åº“
```

---

## ğŸ”§ å¸¸è§é—®é¢˜

### **Q1: Ollama è¿æ¥å¤±è´¥**
```bash
# ç¡®ä¿ Ollama æœåŠ¡è¿è¡Œ
ollama serve

# æµ‹è¯•è¿æ¥
curl http://localhost:11434/api/tags
```

### **Q2: HTML æå–ä¸å®Œæ•´**
- æ£€æŸ¥ `_clean_html()` æ–¹æ³•çš„é€‰æ‹©å™¨
- Wikipedia çš„ä¸»ä½“å†…å®¹åœ¨ `<div class="mw-parser-output">` ä¸­

### **Q3: JSON è§£æå¤±è´¥**
- æ£€æŸ¥ Qwen æ¨¡å‹è¾“å‡ºæ ¼å¼
- è°ƒæ•´ `_extract_json()` æ–¹æ³•çš„è§£æé€»è¾‘
- é™ä½ temperature å‚æ•°æå‡ç¨³å®šæ€§

### **Q4: Pipeline æ‰§è¡Œé¡ºåºé”™è¯¯**
- æ£€æŸ¥ `settings.py` ä¸­çš„ `ITEM_PIPELINES` æ•°å­—é¡ºåº
- æ•°å­—è¶Šå°è¶Šå…ˆæ‰§è¡Œ

---

## ğŸ“š å‚è€ƒæ–‡æ¡£

- [Scrapy å®˜æ–¹æ–‡æ¡£](https://docs.scrapy.org/)
- [Ollama API æ–‡æ¡£](https://github.com/ollama/ollama/blob/main/docs/api.md)
- [BeautifulSoup æ–‡æ¡£](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [Neo4j Python é©±åŠ¨](https://neo4j.com/docs/api/python-driver/current/)

---

**æœ€åæ›´æ–°**: 2025-12-15
**ç»´æŠ¤è€…**: Qoder AI
